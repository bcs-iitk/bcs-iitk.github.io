<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://bcs-iitk.github.io/pages/bcs-iitk/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bcs-iitk.github.io/pages/bcs-iitk/" rel="alternate" type="text/html" /><updated>2021-12-21T14:04:48+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/feed.xml</id><title type="html">BCS @IITK</title><subtitle>Homepage</subtitle><entry><title type="html">Paper Review - A Neural Network Model for Mathematical Development</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/blog-post/2021/11/08/A-Neural-Network-Model-for-Mathematical-Development.html" rel="alternate" type="text/html" title="Paper Review - A Neural Network Model for Mathematical Development" /><published>2021-11-08T00:00:00+00:00</published><updated>2021-11-08T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/blog-post/2021/11/08/A-Neural-Network-Model-for-Mathematical-Development</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/blog-post/2021/11/08/A-Neural-Network-Model-for-Mathematical-Development.html">&lt;p&gt;Paper Link: &lt;a href=&quot;https://pubmed.ncbi.nlm.nih.gov/28019687/&quot;&gt;Improving With Practice: A Neural Model of Mathematical Development&lt;/a&gt; &lt;br /&gt;
Contributor: Suyash Mallik&lt;/p&gt;

&lt;h3 id=&quot;introduction-and-framework&quot;&gt;Introduction and Framework:&lt;/h3&gt;
&lt;p&gt;Scientists have used Spiking Neural Networks (SNNs), to simulate the development of addition abilities in human brains. An SNN is the best model to simulate neurons, because it mimics the time delay present in propagation of signals in natural neurons. To simulate development of math skills, they used two neural networks, working in parallel - a slow network which performed the addition task by counting step-by-step, and a fast network which “memorized” and recalled the outputs of the slow network. The fast and slow networks largely correspond to different kinds of neurons: basal ganglia and cortical neurons, respectively. In humans, it is observed that these two strategies - counting and recall are the predominant strategies in the course of development of mathematical abilities in children. Mimicking the development of human children, the SNN model was found to start off by mainly using the counting strategy, but increasingly relied upon the recall strategy as it learned and got better. The scientists used the Neural Engineering Framework (NEF) to build the model, which uses vector spaces to perform simulated neural computation. In the NEF, groups of neurons act as mathematical functions on vectors. Using the NEF, vectors can be encoded (using encoding vectors) into sequences of firing times for a group of neurons, and the connections between these firing neurons transform the vectors, giving rise to computation. The encoding and decoding vectors of each neuron change as it learns to add (like natural neurons, which change in structure when learning a new skill).&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;https://bcs-iitk.github.io/pages/bcs-iitk/blog-post/img/Blog1-NN_for_Math/strategy_add.jpeg&quot; style=&quot;width:80%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;https://bcs-iitk.github.io/pages/bcs-iitk/blog-post/img/Blog1-NN_for_Math/model_arch.jpg&quot; style=&quot;width:60%;&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;slow-and-fast-networks-explained&quot;&gt;Slow and fast networks, explained.&lt;/h3&gt;
&lt;p&gt;In this model, digits are represented by Semantic Pointers (SPs), which are neural, vector representations used in neural modeling to represent concepts, and the relationships between different concepts (using distances between vectors). Semantic Pointers are similar to pointers in computer science, as they can be “dereferenced” to access large amounts of information. While counting, the slow network uses a single population of neurons, with encoding vectors corresponding to the semantic pointers of each digit from 0-9. The neurons are connected such that they transform the SP of a digit to its increment.&lt;/p&gt;

&lt;p&gt;To implement the recall strategy effectively, the spiking neural network is subject to a supervised learning rule in conjunction with an unsupervised learning rule. Supervised learning is a kind of machine learning where the model learns from an existing “labeled” dataset, and is able to solve problems when faced with new, similar data. In unsupervised learning, the model analyses unlabeled datasets. The fast network uses unsupervised learning to understand the input (the two digits to be added) and supervised learning to retrieve the correct sum from the slow network.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;https://bcs-iitk.github.io/pages/bcs-iitk/blog-post/img/Blog1-NN_for_Math/error_assoc.jpg&quot; style=&quot;width:60%&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;training-the-model-and-conclusions&quot;&gt;Training the model, and conclusions:&lt;/h3&gt;
&lt;p&gt;The rate of learning (how much the model adjusts itself at each step of training) was chosen to be similar to that of cortical neurons in a human child’s brain. In order to decide which strategy (counting vs recall) the SNN would choose to present its final output, a separate set of neurons was constructed which relayed the output of the fast network, only when its relative error was less than 50%.&lt;/p&gt;

&lt;p&gt;Upon training and testing the model, it was found that reaction time fell to a constant value as the SNN learned to rely upon the recall strategy. The same result was also found in human children, who added digits faster once they were confident with the recall strategy. The model also gave significant insights into the mechanism of dyscalculia, a learning disability where the ability to do math is hindered. People with dyscalculia are unable to use the part of their brains which performs the recall strategy effectively, and instead must rely on the counting strategy&lt;/p&gt;</content><author><name></name></author><category term="blog-post" /><summary type="html">Paper Link: Improving With Practice: A Neural Model of Mathematical Development Contributor: Suyash Mallik</summary></entry><entry><title type="html">Convolutional Network for Online Video Understanding</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/CNN-for-online-video-understanding.html" rel="alternate" type="text/html" title="Convolutional Network for Online Video Understanding" /><published>2021-05-16T00:00:00+00:00</published><updated>2021-05-16T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/CNN-for-online-video-understanding</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/CNN-for-online-video-understanding.html">&lt;p&gt;Using UCF101 dataset, we implement high-quality action classification and video captioning within a video, where each video can consist of a few hundred frames. We will look at previous approaches and implement a convolutional network for online video understanding. The network architecture takes long-term content into account and enables fast per-video processing at the same time.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Documentation :&lt;/strong&gt; &lt;a href=&quot;https://drive.google.com/file/d/1Dvee3BAawAiUNqVMRTUC5k4r8yb7-4nU/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Link&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Poster:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://drive.google.com/file/d/1vblimPFo5qTVo25FsfeE41eWRxghR0dy/preview?usp=sharing&quot; style=&quot;width:100%; height:600px;&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="projects" /><summary type="html">Using UCF101 dataset, we implement high-quality action classification and video captioning within a video, where each video can consist of a few hundred frames. We will look at previous approaches and implement a convolutional network for online video understanding. The network architecture takes long-term content into account and enables fast per-video processing at the same time.</summary></entry><entry><title type="html">Finding a correlation in color-perception MRI studies and deep neural network features</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Color-Perception-MRI-DNN.html" rel="alternate" type="text/html" title="Finding a correlation in color-perception MRI studies and deep neural network features" /><published>2021-05-16T00:00:00+00:00</published><updated>2021-05-16T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Color-Perception-MRI-DNN</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Color-Perception-MRI-DNN.html">&lt;p&gt;Multiple studies have been carried out to study how the brain perceives color. Some on macaque monkeys, some on humans. We start with studying the literature on color perception and on the experiments carried out. Then, we look for a dataset of MRI images on which a deep learning analysis can be done. Next, we try to model a deep learning problem on the dataset, for example, a simple classification task. And finally, we try to find a correlation of the data (or of some deep representation of the data) with convolutional neural network features.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Documentation :&lt;/strong&gt;  &lt;a href=&quot;https://drive.google.com/file/d/1MjQy28PZ36dWOtW4wEXfFR3bNj_Sk8GE/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Link&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Poster:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://drive.google.com/file/d/16XBWQKybQ9Omt5HuvtHX2h1SYDvMg7OU/preview?usp=sharing&quot; style=&quot;width:100%; height:600px;&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="projects" /><summary type="html">Multiple studies have been carried out to study how the brain perceives color. Some on macaque monkeys, some on humans. We start with studying the literature on color perception and on the experiments carried out. Then, we look for a dataset of MRI images on which a deep learning analysis can be done. Next, we try to model a deep learning problem on the dataset, for example, a simple classification task. And finally, we try to find a correlation of the data (or of some deep representation of the data) with convolutional neural network features.</summary></entry><entry><title type="html">How can I explain this to you?</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Explainable-AI.html" rel="alternate" type="text/html" title="How can I explain this to you?" /><published>2021-05-16T00:00:00+00:00</published><updated>2021-05-16T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Explainable-AI</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Explainable-AI.html">&lt;p&gt;The motive of the project is to address the major concerns of the deep learning models. The dl models are black boxes needed to be explained. For this part we will learn how we can get insights from the model, about the model. In the second part, we will address another major concern about dl models- Robustness/Vulnerabilities. How the dl models can fooled and how we can overcome these vulnerabilities by defense techniques&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Documentation :&lt;/strong&gt; &lt;a href=&quot;https://drive.google.com/file/d/1-Bridbqkdouv9yfTO_uza_t1chyWqxRy/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Link&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Poster:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://drive.google.com/file/d/12jiO-psUiWRX0XPXXftK7VuXw-ETxWlq/preview?usp=sharing&quot; style=&quot;width:100%; height:600px;&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="projects" /><summary type="html">The motive of the project is to address the major concerns of the deep learning models. The dl models are black boxes needed to be explained. For this part we will learn how we can get insights from the model, about the model. In the second part, we will address another major concern about dl models- Robustness/Vulnerabilities. How the dl models can fooled and how we can overcome these vulnerabilities by defense techniques</summary></entry><entry><title type="html">Speech Emotion Recognition</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Speech-Emotion-Recognition.html" rel="alternate" type="text/html" title="Speech Emotion Recognition" /><published>2021-05-16T00:00:00+00:00</published><updated>2021-05-16T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Speech-Emotion-Recognition</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Speech-Emotion-Recognition.html">&lt;p&gt;Using RAVDESS dataset which contains  around 1500 audio file inputs from 24 different actors (12 male and 12 female ) who recorded short audios in 8 different emotions, we will train a NLP- based model which will be able to detect among the 8 basic emotions as well as the gender of the speaker i.e. Male voice or Female voice.  After training we can deploy this model for predicting with live voices.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Documentation :&lt;/strong&gt; &lt;a href=&quot;https://drive.google.com/file/d/1ZCdvIAxpSDWxYIj4Nytal9SstZU5m3az/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Link&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Poster:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://drive.google.com/file/d/1PsmzCaxg3v899fhk8vF_oC2yWWS900V7/preview?usp=sharing&quot; style=&quot;width:100%; height:600px;&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="projects" /><summary type="html">Using RAVDESS dataset which contains around 1500 audio file inputs from 24 different actors (12 male and 12 female ) who recorded short audios in 8 different emotions, we will train a NLP- based model which will be able to detect among the 8 basic emotions as well as the gender of the speaker i.e. Male voice or Female voice. After training we can deploy this model for predicting with live voices.</summary></entry><entry><title type="html">Analysing Steinmetz dataset to find the role of Hippocampus in Decision Making.</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Steinmetz-Analysis.html" rel="alternate" type="text/html" title="Analysing Steinmetz dataset to find the role of Hippocampus in Decision Making." /><published>2021-05-16T00:00:00+00:00</published><updated>2021-05-16T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Steinmetz-Analysis</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/Steinmetz-Analysis.html">&lt;p&gt;The motive of the project is to learn how to analyse a NeuroImaging data. We start from the basics, learn about brain anatomy and various neuroimaging dataset and various techniques/libraries helpful in analysing data. Then everything learnt to analyse Steinmetz dataset to find the role of a particular brain group [this depends on the student’s interest, for now I have chosen Hippocampus which is involved with memory and learning] in the decision making process. So the aim would be basically to understand the role of memory and learning [at which stage are they required] in a decision making process.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Documentation :&lt;/strong&gt; &lt;a href=&quot;https://drive.google.com/file/d/1AS7RXExJhiUej0P9GjZ8GuVBsIcZQGL9/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Link&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Poster:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://drive.google.com/file/d/1MUpacxqe8JfrD_rpHapUnKEiAhn4K0mI/preview?usp=sharing&quot; style=&quot;width:100%; height:600px;&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="projects" /><summary type="html">The motive of the project is to learn how to analyse a NeuroImaging data. We start from the basics, learn about brain anatomy and various neuroimaging dataset and various techniques/libraries helpful in analysing data. Then everything learnt to analyse Steinmetz dataset to find the role of a particular brain group [this depends on the student’s interest, for now I have chosen Hippocampus which is involved with memory and learning] in the decision making process. So the aim would be basically to understand the role of memory and learning [at which stage are they required] in a decision making process.</summary></entry><entry><title type="html">Models of Memory</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/models-of-memory.html" rel="alternate" type="text/html" title="Models of Memory" /><published>2021-05-16T00:00:00+00:00</published><updated>2021-05-16T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/models-of-memory</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/models-of-memory.html">&lt;p&gt;Human memory can store large amounts of information. Nevertheless, recalling is often a challenging task. In this project we look at the past models of memory retrieval namely the hopfield network and the mean field theory. After the classical models, we also develop a more realistic sequential neural network model for recall tasks(For eg, NTM, MANN etc). After that, we will try to optimize and develop our own models of memory that may be &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Documentation:&lt;/strong&gt; &lt;a href=&quot;https://drive.google.com/file/d/1x_MTrzn0rDEBCB5KxCMltprpQKvsdKvp/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Link&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Poster:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://drive.google.com/file/d/1VgC26PIUFNapT8tkmjUVx-eJp6t1p49C/preview?usp=sharing&quot; style=&quot;width:100%; height:600px;&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="projects" /><summary type="html">Human memory can store large amounts of information. Nevertheless, recalling is often a challenging task. In this project we look at the past models of memory retrieval namely the hopfield network and the mean field theory. After the classical models, we also develop a more realistic sequential neural network model for recall tasks(For eg, NTM, MANN etc). After that, we will try to optimize and develop our own models of memory that may be</summary></entry><entry><title type="html">Why would you do that?</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/neuroeconomics.html" rel="alternate" type="text/html" title="Why would you do that?" /><published>2021-05-16T00:00:00+00:00</published><updated>2021-05-16T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/neuroeconomics</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/projects/2021/05/16/neuroeconomics.html">&lt;p&gt;Neuroeconomics seeks to explain human decision making, the ability to process multiple alternatives and to follow a course of action.In general, a population of people thrives when they depict some sort of social behaviours. Small individual choices can have a big effect on the population. In this project we’ll be taking a look at how multi-agent systems interact and produce macro effects as a result of micro choices, and how those results in turn affect the decisions of the agents. We’ll create a simple agent that can decide whether to show altruistic traits or not, in an artificial environment to maximise it’s chances of survival (We’ll create an environment also), we’ll simulate this on a number of populations with various constraints to find any pattern. Next, (if time permits), we’ll try to create a simple Q-Learning model / any other suitable model to take into account the variability in the agent decisions based on environmental input (reinforcement).&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Documentation :&lt;/strong&gt; &lt;a href=&quot;https://drive.google.com/file/d/1KZZ28eCAJh5KfSdCAuupIV9SdzFE945A/view?usp=sharing&quot; target=&quot;_blank&quot;&gt;Link&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;Poster:&lt;/strong&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://drive.google.com/file/d/1UtAInDTi9ejVc0FELvrc0LumhjTRjgkH/preview?usp=sharing&quot; style=&quot;width:100%; height:600px;&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="projects" /><summary type="html">Neuroeconomics seeks to explain human decision making, the ability to process multiple alternatives and to follow a course of action.In general, a population of people thrives when they depict some sort of social behaviours. Small individual choices can have a big effect on the population. In this project we’ll be taking a look at how multi-agent systems interact and produce macro effects as a result of micro choices, and how those results in turn affect the decisions of the agents. We’ll create a simple agent that can decide whether to show altruistic traits or not, in an artificial environment to maximise it’s chances of survival (We’ll create an environment also), we’ll simulate this on a number of populations with various constraints to find any pattern. Next, (if time permits), we’ll try to create a simple Q-Learning model / any other suitable model to take into account the variability in the agent decisions based on environmental input (reinforcement).</summary></entry><entry><title type="html">Brain and Cognitive Society Online Workshop Jan ‘21</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/events/2021/01/23/BCS-Workshop-Jan-2021.html" rel="alternate" type="text/html" title="Brain and Cognitive Society Online Workshop Jan ‘21" /><published>2021-01-23T00:00:00+00:00</published><updated>2021-01-23T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/events/2021/01/23/BCS-Workshop-Jan-2021</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/events/2021/01/23/BCS-Workshop-Jan-2021.html">&lt;p&gt;This workshop was aimed at introducing the participants to Machine Learning and different aspects of related to it with correspondance to Cognitive models. It comprised of assignments in the form of notebooks over a range of topics, including:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Basic Python&lt;/li&gt;
  &lt;li&gt;Model Fitting&lt;/li&gt;
  &lt;li&gt;Machine Learning&lt;/li&gt;
  &lt;li&gt;Deep Learning&lt;/li&gt;
  &lt;li&gt;Reinforcement Learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The workshop materials were created with the help of different notebooks under the &lt;a href=&quot;https://github.com/NeuromatchAcademy/course-content&quot;&gt;Summer Course&lt;/a&gt; held by &lt;a href=&quot;https://neuromatch.io/academy&quot;&gt;Neuromatch Academy&lt;/a&gt;. The mentioned assignments were edited accordingly by &lt;a href=&quot;https://bcs-iitk.github.io/&quot;&gt;Brain and Cognitive Society, IIT Kanpur&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The github repo containing all the resources and materials is present &lt;a href=&quot;https://github.com/bcs-iitk/BCS_Workshop_Jan_21&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;people-involved-&quot;&gt;People involved :&lt;/h3&gt;
&lt;p&gt;Moderated and Managed by - Harsh &lt;br /&gt;
Assignments Curated by - Harsh, Sandipan, Arpit, Aditya Gupta, Debaditya&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Feel free to &lt;a href=&quot;https://bcs-iitk.github.io/people&quot;&gt;contact us&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="events" /><summary type="html">This workshop was aimed at introducing the participants to Machine Learning and different aspects of related to it with correspondance to Cognitive models. It comprised of assignments in the form of notebooks over a range of topics, including: Basic Python Model Fitting Machine Learning Deep Learning Reinforcement Learning</summary></entry><entry><title type="html">Are ANNs capable of Few-Shot Learning?</title><link href="https://bcs-iitk.github.io/pages/bcs-iitk/journal-club/2021/01/09/Are-ANNs-capable-of-Few-Shot-Leanring.html" rel="alternate" type="text/html" title="Are ANNs capable of Few-Shot Learning?" /><published>2021-01-09T00:00:00+00:00</published><updated>2021-01-09T00:00:00+00:00</updated><id>https://bcs-iitk.github.io/pages/bcs-iitk/journal-club/2021/01/09/Are-ANNs-capable-of-Few-Shot-Leanring</id><content type="html" xml:base="https://bcs-iitk.github.io/pages/bcs-iitk/journal-club/2021/01/09/Are-ANNs-capable-of-Few-Shot-Leanring.html">&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Som V Tambe, an Undergraduate student at the Dept. of Aerospace Engineering, IIT Kanpur.&lt;br /&gt;
&lt;strong&gt;Title:&lt;/strong&gt; Are ANNs capable of Few-Shot Learning?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;br /&gt;
Despite remarkable advances in artificial intelligence and machine learning, machine systems have lagged behind Human Learning in two aspects. First, people can learn a new concept from just one or a handful of examples, whereas standard algorithms in machine learning require tens or hundreds of examples to perform similarly. Second, people learn richer representations than machines do, even for simple concepts, using them for a wider range of functions. Past efforts to counter these problems include
the Bayesian Program Learning, which follows the idea of “how humans do one-shot classification”. The Bayesian Program Learning paper was remarkable but seems to have hand-engineered various parts of the model.&lt;/p&gt;

&lt;p&gt;Our talk focuses on developing more human-like algorithms like One-Shot Learning. This talk will involve Brendan Lake’s paper, as well as other related literature. The speaker shall then discuss the studies he conducted with his mentor, Shashikant Gupta, which provides a completely deep-learning based approach to tackle the Omniglot dataset, and the progress they have achieved with the project.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Slide:&lt;/strong&gt; &lt;a href=&quot;https://drive.google.com/file/d/1RQLN7csbY3u7vV1aEF2ZUd5CZSN3EkLx/view?usp=sharing&quot;&gt;Link&lt;/a&gt; &lt;br /&gt;
&lt;strong&gt;Video:&lt;/strong&gt; &lt;a href=&quot;https://youtu.be/qGuqn1k0ww4&quot;&gt;Youtube&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/qGuqn1k0ww4&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="journal-club" /><summary type="html">Speaker: Som V Tambe, an Undergraduate student at the Dept. of Aerospace Engineering, IIT Kanpur. Title: Are ANNs capable of Few-Shot Learning?</summary></entry></feed>